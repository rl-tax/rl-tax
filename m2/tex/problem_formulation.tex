\section{Problem Definition}

Tax is one tool for a country to reduce inequality. Traditional tax systems are often derived from static models or rely on simplifying assumptions. However, real-world economies are dynamic and complex, featuring uncertain behaviors, heterogeneous agents, and evolving macroeconomic conditions. In this project, we are experimenting with tax policies and observe its effect on equality and productivity. This project is adapted from the work of \cite{zheng_2020_aieconomist}, with some adjustments regarding compute power availability. The problem is formulated as two interconnected Markov Decision Processes (MDPs):
\begin{itemize}
    \item Agents' MDP (inner loop): models the individual behaviors of economic agents.
    \item Planner's MDP (outer loop): models the tax-setting problem to optimize a social welfare function.
\end{itemize}

\subsection{Agents' MDP (Inner Loop)}
Each agent operates in a partially observable environment defined by:
\begin{itemize}
    \item \textbf{State Space ($S$):} 
    \begin{itemize}
        \item Local Spatial Information: Agent's position in a 2D grid and nearby environmental features (e.g., resource tiles, obstacles).
        \item Resource Availability: Status of resource regeneration (e.g., wood and stone).
        \item Agent Attributes: Individual coin endowment, resource inventory, accumulated labor, and skill level (which affects income generation, e.g., coins earned per house built).
        \item Market State: Public trading offers (bids and asks).
        \item Tax Policy: The current tax schedule applied to income.
    \end{itemize}
    
    \item \textbf{Action Space ($A$):}
    \[
    a \in \{\text{Movement, Resource Collection, Building, Trading}\}
    \]
    
    \item \textbf{Transition Function ($T$):} The dynamics update the state based on:
    \begin{itemize}
        \item Movements and interactions (e.g., collisions, blocked paths).
        \item Stochastic resource regeneration.
        \item Market execution and trade outcomes.
        \item Periodic taxation that applies a bracketed tax schedule and redistributes income.
    \end{itemize}
    
    \item \textbf{Reward Function ($r$):} The instantaneous reward for agent $i$ at time $t$ is defined as the change in its utility:
    \[
    r_{i,t} = u(x_{i,t}, l_{i,t}) - u(x_{i,t-1}, l_{i,t-1}),
    \]
    where the utility function is defined as
    \[
    u(x, l) = \frac{x^{1-\eta} - 1}{1-\eta} - l, \quad \eta > 0,
    \]

    with \(x\) representing coins and \(l\) the cumulative labor.
    
    \item \textbf{Discount Factor ($\gamma$):} Each agent maximizes its expected discounted return:
    \[
    \max_{\pi_i} \, \mathbb{E}\left[\sum_{t=0}^{H} \gamma^t\, r_{i,t}\right].
    \]
\end{itemize}

\subsection{Planner's MDP (Outer Loop)}
The planner sets tax policies with the goal of maximizing overall social welfare, based on aggregated economic outcomes.

\begin{itemize}
    \item \textbf{State Space ($S_p$):} The planner observes aggregated indicators:
    \begin{itemize}
        \item Aggregate Wealth Distribution: Summary statistics (e.g., mean, variance, Gini coefficient) of agents' incomes.
        \item Productivity: Total income generated by the agents.
        \item Market and Resource Summaries: Global resource availability and trading volumes.
        \item Tax History: Current and previous tax schedules and tax revenue collections.
    \end{itemize}
    
    \item \textbf{Action Space ($A_p$):} The planner's decision is to set a tax schedule:
    \[
    a_p = [\tau_0, \tau_1, \dots, \tau_{B-1}],
    \]
    where each \(\tau_b \in [0,1]\) is the marginal tax rate for bracket \(b\).
    
    \item \textbf{Transition Function ($T_p$):} The state evolves based on the effect of the tax policy on the agents' behaviors during a tax period. The agentsâ€™ adaptive responses determine the new aggregate economic state.
    
    \item \textbf{Reward Function ($r_p$):} The planner receives a reward based on the improvement in a social welfare function. For example:
    \[
    r_p = \text{swf}(s'_p) - \text{swf}(s_p),
    \]
    where a candidate social welfare function is:
    \[
    \text{swf} = \text{Equality}(x_c) \times \text{Productivity}(x_c),
    \]
    or alternatively a weighted sum of individual utilities:
    \[
    \text{swf} = \sum_{i} \omega_i\, u(x_{c,i}, l_i).
    \]
    
    \item \textbf{Discount Factor ($\gamma_p$):} The planner maximizes:
    \[
    \max_{\pi_p} \, \mathbb{E}\left[\sum_{p=0}^{P} \gamma_p^p\, r_p\right].
    \]
\end{itemize}
